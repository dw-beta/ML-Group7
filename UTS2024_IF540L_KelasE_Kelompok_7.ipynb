{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ffb6ee5",
   "metadata": {},
   "source": [
    "## <div align=\"center\"> UJIAN TENGAH SEMESTER IF540-L MACHINE LEARNING </div>\n",
    "## <div align=\"center\"> Semester Gasal 2024/2025 </div>\n",
    "## <div align=\"center\"> Penerapan Recurrent Neural Network untuk Analisis Sentimen di Sosial Media X </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4aa3c83",
   "metadata": {},
   "source": [
    "---\n",
    "### Kelompok - 7\n",
    "\n",
    "#### Anggota Kelompok : \n",
    "1. Leonardo Tyoes Huibu - 00000065503\n",
    "2. Dylan William - 00000067644\n",
    "3. Eduardus Farrel Tirtawinata - 00000069931\n",
    "4. Emanuel Bernandhika Dwi Friskola - 00000077703\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969da47d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Dataset yang digunakan untuk projek:\n",
    "\n",
    "1. [Sentiment140 dataset with 1.6 million tweets â€“ sumber : https://www.kaggle.com/datasets/kazanova/sentiment140\n",
    "\n",
    "### Hasil kerja"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2af949-ae4a-4fa0-8220-e463d0dbc6bc",
   "metadata": {},
   "source": [
    "#### Column Names\n",
    "##### 1. target: the polarity of the tweet (0 = negative, 2 = neutral, 4 = positive)\n",
    "##### 2. text: the text of the tweet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abfe9f1a-3bbf-4346-b07c-9d6a243ea14d",
   "metadata": {},
   "source": [
    "#### 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38cf589a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target                                               text\n",
       "0       0  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
       "1       0  is upset that he can't update his Facebook by ...\n",
       "2       0  @Kenichan I dived many times for the ball. Man...\n",
       "3       0    my whole body feels itchy and like its on fire \n",
       "4       0  @nationwideclass no, it's not behaving at all...."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read data\n",
    "data = pd.read_csv('tweets.csv', encoding='latin-1', header=None)\n",
    "\n",
    "# Rename columns\n",
    "data.columns = ['target', 'id', 'date', 'flag', 'user', 'text']\n",
    "\n",
    "# Map sentiment labels to binary (0 = negative, 1 = positive)\n",
    "# Replace 4 with 1\n",
    "data['target'] = data['target'].replace(4, 1)\n",
    "\n",
    "# Drop unneeded columsn/features\n",
    "data = data[['target', 'text']]\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e6b529-a59f-4c04-8337-958dc120b766",
   "metadata": {},
   "source": [
    "#### 2. Data Preprocessing (Tokenizing, cleaning text, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21f12a6a-0f58-44c2-be35-06cdefab359b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\dylan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Download stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Function to clean text\n",
    "def clean_tweet(tweet):\n",
    "    tweet = re.sub(r'http\\S+', '', tweet)  # Remove URLs\n",
    "    tweet = re.sub(r'@\\w+', '', tweet)     # Remove mentions\n",
    "    tweet = re.sub(r'#', '', tweet)        # Remove hashtags\n",
    "    tweet = re.sub(r'[^\\w\\s]', '', tweet)  # Remove punctuation\n",
    "    tweet = tweet.lower()                  # Convert to lowercase\n",
    "    return tweet\n",
    "\n",
    "# Apply the cleaning function to the tweets\n",
    "data['cleaned_text'] = data['text'].apply(clean_tweet)\n",
    "\n",
    "# Tokenization and padding\n",
    "max_words = 20000  # Maximum number of words in the vocabulary\n",
    "max_len = 100      # Maximum length of each tweet\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(data['cleaned_text'])\n",
    "\n",
    "# Convert tweets to sequences\n",
    "sequences = tokenizer.texts_to_sequences(data['cleaned_text'])\n",
    "\n",
    "# Pad sequences to ensure uniform length\n",
    "X = pad_sequences(sequences, maxlen=max_len)\n",
    "\n",
    "# Target variable\n",
    "y = data['target'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e024a382-d906-4172-9ff0-1409c950f52a",
   "metadata": {},
   "source": [
    "#### Compare Data To See Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8f97d9a-c445-4d47-ba70-b9689e75a89b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Uncleaned_Tweet</th>\n",
       "      <th>Cleaned_Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "      <td>awww thats a bummer  you shoulda got david ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "      <td>is upset that he cant update his facebook by t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "      <td>i dived many times for the ball managed to sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "      <td>no its not behaving at all im mad why am i he...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>@Kwesidei not the whole crew</td>\n",
       "      <td>not the whole crew</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Need a hug</td>\n",
       "      <td>need a hug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>@LOLTrish hey  long time no see! Yes.. Rains a...</td>\n",
       "      <td>hey  long time no see yes rains a bit only a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>@Tatiana_K nope they didn't have it</td>\n",
       "      <td>nope they didnt have it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>@twittera que me muera ?</td>\n",
       "      <td>que me muera</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Uncleaned_Tweet  \\\n",
       "0  @switchfoot http://twitpic.com/2y1zl - Awww, t...   \n",
       "1  is upset that he can't update his Facebook by ...   \n",
       "2  @Kenichan I dived many times for the ball. Man...   \n",
       "3    my whole body feels itchy and like its on fire    \n",
       "4  @nationwideclass no, it's not behaving at all....   \n",
       "5                      @Kwesidei not the whole crew    \n",
       "6                                        Need a hug    \n",
       "7  @LOLTrish hey  long time no see! Yes.. Rains a...   \n",
       "8               @Tatiana_K nope they didn't have it    \n",
       "9                          @twittera que me muera ?    \n",
       "\n",
       "                                       Cleaned_Tweet  \n",
       "0     awww thats a bummer  you shoulda got david ...  \n",
       "1  is upset that he cant update his facebook by t...  \n",
       "2   i dived many times for the ball managed to sa...  \n",
       "3    my whole body feels itchy and like its on fire   \n",
       "4   no its not behaving at all im mad why am i he...  \n",
       "5                                not the whole crew   \n",
       "6                                        need a hug   \n",
       "7   hey  long time no see yes rains a bit only a ...  \n",
       "8                           nope they didnt have it   \n",
       "9                                     que me muera    "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison_df = pd.DataFrame({\n",
    "    'Uncleaned_Tweet': data['text'],        # Original uncleaned tweets\n",
    "    'Cleaned_Tweet': data['cleaned_text']   # Cleaned tweets after preprocessing\n",
    "})\n",
    "\n",
    "# Display the first 10 rows to compare\n",
    "comparison_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce35bcb-49bf-403b-9152-c95a0014cd66",
   "metadata": {},
   "source": [
    "#### 4. Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c324c45-42ae-4413-a83d-5583c48e938c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split Done\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(\"Split Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff04aba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!jupyter nbconvert --to html \"./UTS2024_IF540L_KelasE_Kelompok_7.ipynb\" --output-dir=\"./\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d142d46",
   "metadata": {},
   "source": [
    "### Next step:\n",
    "* convert the generated html file to PDF using the online tool: https://www.sejda.com/html-to-pdf\n",
    "* choose the following settings:\n",
    "    * Page size: One long page\n",
    "    * Page Orientation: auto\n",
    "    * Use print stylesheet\n",
    "* Submit your ipython notebook and PDF files\n",
    "\n",
    "Markdown basics https://markdown-guide.readthedocs.io/en/latest/basics.html#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
